# -*- coding: utf-8 -*-
"""Projeto final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16HrONViOFsGu2Sd3gA4xFkeYNo6KhzIL

### Importação e instalação de bibliotecas
"""

pip install pymongo[srv]

!pip install gcsfs

!pip install pyspark

# Importação de bibliotecas:

import pandas as pd
from google.cloud import storage
import os
from pyspark.sql.functions import udf, monotonically_increasing_id
from pyspark.sql import SparkSession
from pyspark import SparkConf
import pyspark.sql.functions as F
from pyspark.sql.types import *

"""# Pandas

### Importação dos datasets
"""

# datasets csv:

df_mundo = pd.read_csv("https://storage.googleapis.com/projeto_grupo/datasets_originais/datasets_csv/Continent_Consumption_TWH.csv")
df_paises = pd.read_csv("https://storage.googleapis.com/projeto_grupo/datasets_originais/datasets_csv/Country_Consumption_TWH.csv")

# dataset xlsx:

df_xlsx = pd.read_excel("https://storage.googleapis.com/projeto_grupo/datasets_originais/datasets_txt/dataset_xls/owid-energy-data(2).xlsx")

"""### Backup dos originais:"""

df_mundo_1 = df_mundo.copy()
df_paises_1 = df_paises.copy()

df_xlsx_1 = df_xlsx.copy()

df_xlsx_1.head(0)

"""## Tratamento dos datasets csv"""

# comando para mostrar todas as colunas do df:
pd.set_option('max_columns', None)

# Tradução dos datasets df_paises_1 e df_xlsx_1:

df_paises_1.rename(
    columns={'Year':'Ano',
             'United States':'Estados_Unidos',
             'Brazil':'Brasil',
             'Belgium':'Belgica',
             'Czechia':'Republica_Tcheca',
             'France':'Franca',
             'Germany':'Alemanha',
             'Italy':'Italia',
             'Netherlands':'Holanda',
             'Poland':'Polonia',
             'Romania':'Romenia',
             'Spain':'Espanha',
             'Sweden':'Suecia',
             'United Kingdom':'Reino_Unido',
             'Norway':'Noruega',
             'Turkey':'Turquia',
             'Kazakhstan':'Cazaquistao',
             'Ukraine':'Ucrania',
             'Uzbekistan':'Uzbequistao',
             'Japan':'Japao',
             'Malaysia':'Malasia',
             'South Korea':'Coreia_do_Sul',
             'Thailand':'Tailandia',
             'New Zealand':'Nova_Zelandia',
             'Egypt':'Egito',
             'South Africa':'Africa_do_Sul',
             'Iran':'Ira',
             'Saudi Arabia':'Arabia_Saudita',
             'United Arab Emirates':'Emirados_Arabes_Unidos'
    },inplace=True)

df_mundo_1.rename(
    columns = {
        'Year': 'Ano',
        'World': 'Mundo',
        'OECD': 'Organizacao para a Cooperacao e Desenvolvimento Economico (OECD)',
        'BRICS': 'BRICS',
        'Europe': ' Europa',
        'North America': 'America do Norte',
        'Latin America': 'America Latina',
        'Asia': 'Asia',
        'Pacific': 'Pacifico',
        'Middle-East': 'Oriente Medio',
        'CIS': 'Comunidade dos Estados Independentes (CEI)'
        },inplace=True)

#verificando a quantidade de linhas e colunas
#df_mundo_1.shape
df_paises_1.shape

df_paises_1.head(1)

#dropando eventuais linhas duplicadas

df_mundo_1 = df_mundo_1.drop_duplicates()
df_paises_1 = df_paises_1.drop_duplicates()

#ao usar o shape novamente, verifica que não havia linhas duplicadas, uma vez que o shape se manteve

df_mundo_1.shape
df_paises_1.shape

# Verificação dos tipos de cada coluna:

df_mundo_1.info()
print("")
df_paises_1.info()

# Verificação de valores nulos ou inconsistências:

#df_mundo_1.isna().sum()
df_paises_1.isna().sum()

# No df_paises_1, verificar se há NaN usando o sorted:

sorted(pd.unique(df_paises_1['Ano']))

# Descobrimos que a última linha é de apenas valores NaN:

df_paises_1.tail(5)

# Remover todas as linhas que possuem apenas valores NaN:

df_paises_1 = df_paises_1.dropna(how="all")

df_paises_1.tail(5)

# Conversão dos tipos de colunas:

df_paises_1['Ano'] = df_paises_1['Ano'].astype('int')

"""## Tratamento do dataset xlsx

### Drop de linhas em função do ano:
"""

df_xlsx_1.dtypes

# conferir dimensões do dataset xlsx
df_xlsx_1.shape

# Percebemos que a faixa de anos é de 1900 a 2021:
sorted(pd.unique(df_xlsx_1['year']))

# Exclusão das linhas anteriores a 1990 para que o dataset df_xlsx_1 seja compatível com os datasets anteriores:

linhas_excluir = df_xlsx_1[df_xlsx_1['year'] < 1990].index

df_xlsx_1.drop(linhas_excluir, inplace=True)

# Exclusão das linha de 2021:

linhas_excluir2 = df_xlsx_1[df_xlsx_1['year'] > 2020].index

df_xlsx_1.drop(linhas_excluir2, inplace=True)

# conferir dimensões do dataset xlsx
df_xlsx_1.shape

"""### Drop de linhas em função do país:
- serão dropadas linhas no df_xlsx_1 cujos países que não estão no df_paises_1
"""

# lista de países do df_paises:

lista_df_paises = list(df_paises.columns)

sorted(lista_df_paises)

#lista de paises do df_xlsx:

lista_df_xlsx_1 = sorted(pd.unique(df_xlsx_1['country']))

lista_df_xlsx_1

# Operação com for para excluir linhas no df_xlsx_1 cujos países não estão no df_paises_1:

# list(set(lista_df_paises).intersection(lista_df_xlsx_1))

for pais_x in lista_df_xlsx_1:
  contador = 0
  for pais_p in lista_df_paises:
    if pais_x == pais_p:
      continue
    else:
      contador += 1
      if contador == len(lista_df_paises):
        excluir_linha = df_xlsx_1[df_xlsx_1['country'] == pais_x].index
        df_xlsx_1.drop(excluir_linha, inplace = True)
      else:
        continue

# Verificação da nova quantidade de linhas:
df_xlsx_1.shape

# Verificação do tamanhos das duas listas (sendo que o primeiro valor de lista_df_paises é "Year")

#len(lista_df_paises)
sorted(pd.unique(df_xlsx_1['country']))

"""### Drop de colunas:"""

# backup antes do drop de colunas:
df_xlsx_2 = df_xlsx_1.copy()

# Lista de colunas no df_xlsx_1 (o índice na lista será sempre dois números a menos que o do texto acima)
len(list(df_xlsx_2.columns))

# A lista de colunas no site que possui o dataset está errada. 
# Criamos uma nova lista para auxiliar o drop de colunas do projeto.

lista_git = [
  'iso_code',
  'country',
  'year',
  'coal_prod_change_pct',
  'coal_prod_change_twh',
  'gas_prod_change_pct',
  'gas_prod_change_twh',
  'oil_prod_change_pct',
  'oil_prod_change_twh',
  'energy_cons_change_pct',
  'energy_cons_change_twh',
  'biofuel_share_elec',
  'biofuel_cons_change_pct',
  'biofuel_share_energy',
  'biofuel_cons_change_twh',
  'biofuel_consumption',
  'biofuel_elec_per_capita',
  'biofuel_cons_per_capita',
  'carbon_intensity_elec',
  'coal_share_elec',
  'coal_cons_change_pct',
  'coal_share_energy',
  'coal_cons_change_twh',
  'coal_consumption',
  'coal_elec_per_capita',
  'coal_cons_per_capita',
  'coal_production',
  'coal_prod_per_capita',
  'electricity_generation',
  'biofuel_electricity',
  'coal_electricity',
  'fossil_electricity',
  'gas_electricity',
  'hydro_electricity',
  'nuclear_electricity',
  'oil_electricity',
  'other_renewable_electricity',
  'other_renewable_exc_biofuel_electricity',
  'renewables_electricity',
  'solar_electricity',
  'wind_electricity',
  'energy_per_gdp',
  'energy_per_capita',
  'fossil_cons_change_pct',
  'fossil_share_energy',
  'fossil_cons_change_twh',
  'fossil_fuel_consumption',
  'fossil_energy_per_capita',
  'fossil_cons_per_capita',
  'fossil_share_elec',
  'gas_share_elec',
  'gas_cons_change_pct',
  'gas_share_energy',
  'gas_cons_change_twh',
  'gas_consumption',
  'gas_elec_per_capita',
  'gas_energy_per_capita',
  'gas_production',
  'gas_prod_per_capita',
  'hydro_share_elec',
  'hydro_cons_change_pct',
  'hydro_share_energy',
  'hydro_cons_change_twh',
  'hydro_consumption',
  'hydro_elec_per_capita',
  'hydro_energy_per_capita',
  'low_carbon_share_elec',
  'low_carbon_electricity',
  'low_carbon_elec_per_capita',
  'low_carbon_cons_change_pct',
  'low_carbon_share_energy',
  'low_carbon_cons_change_twh',
  'low_carbon_consumption',
  'low_carbon_energy_per_capita',
  'nuclear_share_elec',
  'nuclear_cons_change_pct',
  'nuclear_share_energy',
  'nuclear_cons_change_twh',
  'nuclear_consumption',
  'nuclear_elec_per_capita',
  'nuclear_energy_per_capita',
  'oil_share_elec',
  'oil_cons_change_pct',
  'oil_share_energy',
  'oil_cons_change_twh',
  'oil_consumption',
  'oil_elec_per_capita',
  'oil_energy_per_capita',
  'oil_production',
  'oil_prod_per_capita',
  'other_renewables_elec_per_capita',
  'other_renewables_elec_per_capita_exc_biofuel',
  'other_renewables_share_elec',
  'other_renewables_share_elec_exc_biofuel',
  'other_renewables_cons_change_pct',
  'other_renewables_share_energy',
  'other_renewables_cons_change_twh',
  'other_renewable_consumption',
  'other_renewables_energy_per_capita',
  'per_capita_electricity',
  'population',
  'primary_energy_consumption',
  'renewables_elec_per_capita',
  'renewables_share_elec',
  'renewables_cons_change_pct',
  'renewables_share_energy',
  'renewables_cons_change_twh',
  'renewables_consumption',
  'renewables_energy_per_capita',
  'solar_share_elec',
  'solar_cons_change_pct',
  'solar_share_energy',
  'solar_cons_change_twh',
  'solar_consumption',
  'solar_elec_per_capita',
  'solar_energy_per_capita',
  'gdp',
  'wind_share_elec',
  'wind_cons_change_pct',
  'wind_share_energy',
  'wind_cons_change_twh',
  'wind_consumption',
  'wind_elec_per_capita',
  'wind_energy_per_capita']

lista_indice = [1,2,11,13,15,19,21,23,28,29,30,32,33,34,35,38,39,40,50,52,54,59,61,63,74,76,78,81,83,85,100,109,111,113,117,119,121]

nova_lista = []

for i in lista_git:
  if lista_git.index(i) in lista_indice:
    nova_lista.append(i)

nova_lista

# Drop de colunas:

lista_xlsx = list(df_xlsx_2.columns)

for j in lista_git:
  if j not in nova_lista:
    df_xlsx_2.drop(f'{j}',axis=1, inplace=True)

"""## Tradução do dataset"""

df_xlsx_2.rename(
    columns = {
        'country': 'Pais',
        'year': 'Ano',
        'biofuel_share_elec': 'Geracao_de_eletricidade_por_biocombustiveis',
        'biofuel_share_energy': 'Consumo_de_energia_primaria_de_biocombustiveis',
        'biofuel_consumption': 'Consumo_de_energia_primaria_de_biocombustiveis_em_TWh',
        'coal_share_elec': 'Geracao_de_eletricidade_por_carvao',
        'coal_share_energy': 'Consumo_de_energia_primaria_de_carvao',
        'coal_consumption': 'Consumo_de_energia_primaria_de_carvao_em_TWh',
        'electricity_generation': 'Geracao_de_eletricidade_em_TWh',
        'biofuel_electricity': 'Geracao_de_eletricidade_por_biocombustiveis_em_TWh',
        'coal_electricity': 'Geracao_de_eletricidade_por_carvao_em_TWh',
        'gas_electricity' : 'Geracao_de_eletricidade_por_gas_em_TWh',
        'hydro_electricity' : 'Geracao_de_eletricidade_por_energia_hidreletrica_em_TWh',
        'nuclear_electricity' : 'Geracao_de_eletricidade_por_energia_nuclear_em_TWh',
        'oil_electricity' : 'Geracao_de_eletricidade_por_petroleo_em_TWh',
        'renewables_electricity' : 'Geracao_de_eletricidade_por_energias_renovaveis_em_TWh',
        'solar_electricity' : 'Geracao_de_eletricidade_por_energia_solar_em_TWh',
        'wind_electricity' : 'Geracao_de_eletricidade_por_energia_eolica_em_TWh',
        'gas_share_energy' : 'Consumo_de_energia_primaria_de_gas',
        'gas_consumption' : 'Consumo_de_energia_primaria_de_gas_em_TWh',
        'hydro_share_energy' : 'Consumo_de_energia_primaria_de_fonte_hidreletrica',
        'hydro_consumption' : 'Consumo_de_energia_primaria_de_fonte_hidreletrica_em_TWh',
        'nuclear_share_elec' : 'Geracao_de_eletricidade_por_energia_nuclear',
        'nuclear_consumption' : 'Consumo_de_energia_primaria_de_fonte_nuclear_em_TWh',
        'oil_share_elec' : 'Geracao_de_eletricidade_de_petroleo',
        'oil_share_energy' : 'Consumo_de_energia_primaria_de_petroleo',
        'oil_consumption' : 'Consumo_de_energia_primaria_de_petroleo_em_TWh',
        'solar_share_elec' : 'Geracao_de_eletricidade_de_fonte_solar',
        'solar_share_energy' : 'Consumo_de_energia_primaria_de_fonte_solar',
        'solar_consumption' : 'Consumo_de_energia_primaria_de_fonte_solar_em_TWh',
        'wind_share_elec' : 'Geracao_de_eletricidade_de_fonte_eolica',
        'wind_share_energy' : 'Consumo_de_energia_primaria_de_fonte_eolica',
        'wind_consumption' : 'Consumo_de_energia_primaria_de_fonte_eolica_em_TWh',
        'nuclear_share_energy' : 'Consumo_de_energia_primaria_de_fonte_nuclear',
        'hydro_share_elec' : 'Geracao_de_eletricidade_de_fonte_hidreletrica',
        'gas_share_elec' : 'Geracao_de_eletricidade_de_gas',
        'population':'Populacao'
        },inplace=True)

# Mudança do tipo da coluna população para int:

df_xlsx_2['Populacao'] = df_xlsx_2['Populacao'].astype('int')

# Tradução coluna paises

traducao = {
 'United States':'Estados_Unidos',
  'Brazil':'Brasil',
  'Belgium':'Belgica',
  'Czechia':'Republica_Tcheca',
  'France':'Franca',
  'Germany':'Alemanha',
  'Italy':'Italia',
  'Netherlands':'Holanda',
  'Poland':'Polonia',
  'Romania':'Romenia',
  'Spain':'Espanha',
  'Sweden':'Suecia',
  'United Kingdom':'Reino_Unido',
  'Norway':'Noruega',
  'Turkey':'Turquia',
  'Kazakhstan':'Cazaquistao',
  'Ukraine':'Ucrania',
  'Uzbekistan':'Uzbequistao',
  'Japan':'Japao',
  'Malaysia':'Malasia',
  'South Korea':'Coreia_do_Sul',
  'Thailand':'Tailandia',
  'New Zealand':'Nova_Zelandia',
  'Egypt':'Egito',
  'South Africa':'Africa_do_Sul',
  'Iran':'Ira',
  'Saudi Arabia':'Arabia_Saudita',
  'United Arab Emirates':'Emirados_Arabes_Unidos',
}

df_xlsx_2['Pais'].replace(traducao, inplace = True)

"""Verificação de valores nulos, NaN, Na, e tipos de colunas"""

# Tipos das colunas:
df_xlsx_2.dtypes

# Verificação da quantidades de valores Na e nulos em cada coluna:

df_xlsx_2.isnull().values.any()
df_xlsx_2.isna().sum()

"""A decisão tomada foi de não alterar os valores de NaN no dataframe. Há países que não possuem determinada fonte de energia ou que não existem registros em determinada faixa de anos. Dessa forma, é adequado que os valores NaN permaneçam."""

df_paises_1.head(5)

df_mundo_1.head(5)

df_xlsx_2.head(5)

"""# PySpark

Criação das tabelas a partir dos dataframes do pandas:
"""

# Criação da sparksession:

spark = (
    SparkSession.builder
                .master("local")
                .appName("projeto_final")
                .config("spark.ui.port", "4050")
                .getOrCreate()
)

"""### Criação dos schemas"""

# Schema para a tabela df_spark_paises

schemapaises = StructType([
                  StructField('Ano',IntegerType(),True),
                  StructField('China',FloatType(),True),
                  StructField('Estados_Unidos',FloatType(),True),
                  StructField('Brasil',FloatType(),True),
                  StructField('Belgica',FloatType(),True),
                  StructField('Republica_Tcheca',FloatType(),True),
                  StructField('Franca',FloatType(),True),
                  StructField('Alemanha',FloatType(),True),
                  StructField('Italia',FloatType(),True),
                  StructField('Holanda',FloatType(),True),
                  StructField('Polonia',FloatType(),True),
                  StructField('Portugal',FloatType(),True),
                  StructField('Romenia',FloatType(),True),
                  StructField('Espanha',FloatType(),True),
                  StructField('Suecia',FloatType(),True),
                  StructField('Reino_Unido',FloatType(),True),
                  StructField('Noruega',FloatType(),True),
                  StructField('Turquia',FloatType(),True),
                  StructField('Cazaquistao',FloatType(),True),
                  StructField('Russia',FloatType(),True),
                  StructField('Ucrania',FloatType(),True),
                  StructField('Uzbequistao',FloatType(),True),
                  StructField('Argentina',FloatType(),True),
                  StructField('Canada',FloatType(),True),
                  StructField('Chile',FloatType(),True),
                  StructField('Colombia',FloatType(),True),
                  StructField('Mexico',FloatType(),True),
                  StructField('Venezuela',FloatType(),True),
                  StructField('Indonesia',FloatType(),True),
                  StructField('Japao',FloatType(),True),
                  StructField('Malasia',FloatType(),True),
                  StructField('Coreia_do_Sul',FloatType(),True),
                  StructField('Taiwan',FloatType(),True),
                  StructField('Tailandia',FloatType(),True),
                  StructField('India',FloatType(),True),
                  StructField('Australia',FloatType(),True),
                  StructField('Nova_Zelandia',FloatType(),True),
                  StructField('Algeria',FloatType(),True),
                  StructField('Egito',FloatType(),True),
                  StructField('Nigeria',FloatType(),True),
                  StructField('Africa_do_Sul',FloatType(),True),
                  StructField('Ira',FloatType(),True),
                  StructField('Kuwait',FloatType(),True),
                  StructField('Arabia_Saudita',FloatType(),True),
                  StructField('Emirados_Arabes_Unidos',FloatType(),True)
])

df_spark_paises = spark.createDataFrame(df_paises_1, schema = schemapaises)

df_spark_paises.show(5)

# Schema para a df_spark_mundo

schemamundo = (
    StructType([
              StructField('Ano', IntegerType(), True),
              StructField('Mundo', FloatType(), True),
              StructField('Organizacao_para_a_Cooperacao_e_Desenvolvimento_Economico_(OECD)', FloatType(), True),
              StructField('BRICS', FloatType(), True),
              StructField('Europa', FloatType(), True),
              StructField('Americado_Norte',FloatType(), True),
              StructField('America_Latina', FloatType(), True),
              StructField('Asia', FloatType(), True),
              StructField('Pacifico', FloatType(), True),
              StructField('Africa', FloatType(), True),
              StructField('Oriente_Medio', FloatType(), True),
              StructField('Comunidade_dos_Estados_Independentes_(CEI)', FloatType(), True),
  ])
)

df_spark_mundo = spark.createDataFrame(df_mundo_1, schema=schemamundo)

df_spark_mundo.show(5)

# backup do df_xlsx_2:

df_xlsx_3 = df_xlsx_2

# Schema para a df_spark_xlsx:

schemaxlsx = (
    StructType([
              StructField('Pais',StringType(), True),
              StructField('Ano', IntegerType(), True),
              StructField('Geracao_de_eletricidade_por_biocombustiveis', FloatType(), True),
              StructField('Consumo_de_energia_primaria_de_biocombustiveis', FloatType(), True),
              StructField('Consumo_de_energia_primaria_de_biocombustiveis_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_carvao', FloatType(), True),
              StructField('Consumo_de_energia_primaria_de_carvao', FloatType(), True),
              StructField('Consumo_de_energia_primaria_de_carvao_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_biocombustiveis_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_carvao_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_gas_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_energia_hidreletrica_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_energia_nuclear_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_petroleo_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_energias_renovaveis_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_energia_solar_em_TWh', FloatType(), True),
              StructField('Geracao_de_eletricidade_por_energia_eolica_em_TWh',FloatType(),True),
              StructField('Geracao_de_eletricidade_em_TWh',FloatType(),True),
              StructField('Geracao_de_eletricidade_de_gas',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_gas',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_gas_em_TWh',FloatType(),True),
              StructField('Geracao_de_eletricidade_de_fonte_hidreletrica',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_fonte_hidreletrica',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_fonte_hidreletrica_em_TWh',FloatType(),True),
              StructField('Geracao_de_eletricidade_por_energia_nuclear',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_fonte_nuclear',FloatType(),True),     
              StructField('Consumo_de_energia_primaria_de_fonte_nuclear_em_TWh',FloatType(),True),
              StructField('Geracao_de_eletricidade_de_petroleo',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_petroleo',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_petroleo_em_TWh',FloatType(),True),
              StructField('Populacao',IntegerType(),True),
              StructField('Geracao_de_eletricidade_de_fonte_solar',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_fonte_solar',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_fonte_solar_em_TWh',FloatType(),True),
              StructField('Geracao_de_eletricidade_de_fonte_eolica',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_fonte_eolica',FloatType(),True),
              StructField('Consumo_de_energia_primaria_de_fonte_eolica_em_TWh',FloatType(),True)
    ])
)

df_spark_xlsx = spark.createDataFrame(df_xlsx_3, schema=schemaxlsx)

df_spark_xlsx.select(F.col('Pais'),F.col('Ano'),F.col('Populacao')).filter(F.col('Ano') == 2020).show(100)

"""##Insights PySpark

1) PySpark: Criação de coluna com consumo total de eletricidade gerada por fonte renovável e outra por fonte não renovável (df_xlsx_3)

2) PySpark: Criação de coluna com consumo total do país no último ano / populacao (df_xlsx_3)

### Insight 1:

Criação de novas colunas:
"""

# Criação de coluna com consumo total de eletricidade por fonte renovável:

df_spark_xlsx = df_spark_xlsx.withColumn('Consumo_total_de_eletricidade_gerada_por_fonte_renovavel_em_TWh',
                                         F.col('Consumo_de_energia_primaria_de_biocombustiveis_em_TWh') + 
                                         F.col('Consumo_de_energia_primaria_de_fonte_hidreletrica_em_TWh') + 
                                         F.col('Consumo_de_energia_primaria_de_fonte_solar_em_TWh') + 
                                         F.col('Consumo_de_energia_primaria_de_fonte_eolica_em_TWh') 
                                         )

# Conversão da coluna para o tipo Float:
df_spark_xlsx.select(F.col("Consumo_total_de_eletricidade_gerada_por_fonte_renovavel_em_TWh").cast("float"))

df_spark_xlsx.dtypes

# Criação de coluna com consumo total de eletricidade por fonte não renovável:

df_spark_xlsx = df_spark_xlsx.withColumn('Consumo_total_de_eletricidade_gerada_por_fonte_nao_renovavel_em_TWh',
                                         F.col('Consumo_de_energia_primaria_de_carvao_em_TWh') + 
                                         F.col('Consumo_de_energia_primaria_de_fonte_nuclear_em_TWh') + 
                                         F.col('Consumo_de_energia_primaria_de_petroleo_em_TWh') + 
                                         F.col('Consumo_de_energia_primaria_de_gas_em_TWh') 
                                         )

# Conversão da coluna para o tipo Float:
df_spark_xlsx.select(F.col("Consumo_total_de_eletricidade_gerada_por_fonte_nao_renovavel_em_TWh").cast("float"))

df_insight_1 = df_spark_xlsx.select(F.col('Pais'),
                                    F.col('Ano'),
                                    F.col('Consumo_total_de_eletricidade_gerada_por_fonte_renovavel_em_TWh'),
                                    F.col('Consumo_total_de_eletricidade_gerada_por_fonte_nao_renovavel_em_TWh'))

df_insight_1.show()

"""### Insight 2:"""

df_insight_2 = df_spark_xlsx.select("Pais","Populacao").filter(F.col("Ano") == 2020)

# Dataframe apenas com os nomes das colunas de df_paises em ordem alfabética

# Consumo total de eletricidade de cada país no df_paises em 2020:
linha = df_paises_teste.loc[df_paises['Year'] == 2020].values

# Transformação do array em lista:
lista = linha[0].tolist()

# Remover o primeiro item (2020):
lista = lista[1:]

df_insight_2 = df_insight_2.repartition(1).withColumn(
    "Consumo_em_kWh", 
    udf(lambda id: lista[id])(monotonically_increasing_id()))

df_insight_2 = df_insight_2.withColumn('Consumo_em_kWh',F.col('Consumo_em_kWh') * 1000000
)

df_insight_2 = df_insight_2.withColumn(
    'Consumo_per_Capita_em_kWh', F.col('Consumo_em_kWh') / F.col('Populacao')
)

df_insight_2.show()

"""## SparkSQL

3) sparkSQL: groupby do consumo total dos países de 1990 a 2020 para mostrar essa taxa de crescimento. (df_paises_1)

Insight: quanto maior o crescimento, maior a necessidade de desenvolvimento do mercado de energia renovável

4) sparkSQL: o mesmo insight do 3, mas para continentes (df_mundo_1)

### Insight 3:
"""

# Lista de países:

lista_paises = list(df_paises_1.columns)

# lista de consumo de eletricidade por país em 1990:

lista_1990 = df_paises_1.loc[0]
lista_1990 = list(lista_1990)

# lista de consumo de eletricidade por país em 2020:

lista_2020 = df_paises_1.loc[30]
lista_2020 = list(lista_2020)

# Lista da diferença entre consumo de eletricidade por país entre 2020 e 1990:

lista_final = []
for i in range(45):
  lista_final.append(lista_2020[i] - lista_1990[i])

# Lista da diferença em %:

lista_final_100 = []
for i in range(45):
  diferenca = lista_2020[i] - lista_1990[i]
  diferenca_100 = (diferenca/lista_1990[i])*100
  item = round(diferenca_100,2)
  lista_final_100.append(item)

len(lista_final_100)

# Retirada do primeiro item de cada lista (respectivamente 'Ano', '1990', '2020', '30'):

lista_paises.pop(0)
lista_1990.pop(0)
lista_2020.pop(0)
lista_final.pop(0)
lista_final_100.pop(0)

# Criação do schema, dados e dataframe:

esquema = ['Pais','1990','2020','Diferenca_de_consumo_entre_anos','Taxa_de_variacao (%)']

dados = []
for i in range(44):
  dados.append((lista_paises[i],lista_1990[i],lista_2020[i],lista_final[i],lista_final_100[i]))

df_insight_3 = spark.createDataFrame(data = dados, schema = esquema)

df_insight_3.show(50)

# criação da tabela do dataframe df_insight_3:

df_insight_3.createOrReplaceTempView("df_sql_3")

spark.sql('SELECT * FROM df_sql_3 ORDER BY Diferenca_de_consumo_entre_anos DESC').show(50)

"""### Insight 4"""

# Lista de continentes:

lista_continentes = list(df_mundo_1.columns)
lista_continentes

# lista de consumo de eletricidade por continente em 1990:

lista_1990c = df_mundo_1.loc[0]
lista_1990c = list(lista_1990c)

# lista de consumo de eletricidade por país em 2020:

lista_2020c = df_mundo_1.loc[30]
lista_2020c = list(lista_2020c)

# Lista da diferença entre consumo de eletricidade por país entre 2020 e 1990:

lista_finalc = []
for i in range(12):
  diferenca = round((lista_2020c[i] - lista_1990c[i]),2)
  lista_finalc.append(diferenca)

# Lista da diferença em %:

lista_finalc_100 = []
for i in range(12):
  diferencac = lista_2020c[i] - lista_1990c[i]
  diferencac_100 = (diferencac/lista_1990c[i])*100
  item = round(diferencac_100,2)
  lista_finalc_100.append(item)

len(lista_finalc_100)

# Retirada do primeiro item de cada lista (respectivamente '1990', '2020', '30'):

lista_1990c.pop(0)
lista_2020c.pop(0)
lista_finalc.pop(0)
lista_finalc_100.pop(0)

# Retirada dos grupos de continentes considerando a alteração do indice a cada pop (respectivamente 'Ano','OECD','BRICS','Oriente Medio','CEI'):

lista_continentes.pop(0)   
lista_continentes.pop(1) 
lista_continentes.pop(1)
lista_continentes.pop(7)
lista_continentes.pop(7)

lista_continentes

# Criação do schema, dados e dataframe:

esquema = ['Continente','1990','2020','Diferenca_de_consumo_entre_anos','Taxa_de_variacao (%)']

dados = []
for i in range(7):
  dados.append((lista_continentes[i],lista_1990c[i],lista_2020c[i],lista_finalc[i],lista_finalc_100[i]))

df_insight_4 = spark.createDataFrame(data = dados, schema = esquema)

df_insight_4.show()

# criação da tabela do dataframe df_insight_4:

df_insight_4.createOrReplaceTempView("df_sql_4")

# Uso do comando WHERE para retirar os valores correspondentes a linha 'Mundo'

spark.sql('SELECT * FROM df_sql_4 WHERE Continente != "Mundo"').show()

# Uso do comando WHERE para visualizar apenas a linha 'Mundo'

spark.sql('SELECT * FROM df_sql_4 WHERE Continente == "Mundo"').show()

"""# Big Query

5) Bigquery: Ranking de países que produziram mais com fonte renovável e não renovável em 2020 (último ano registrado)

6) Bigquery: Percentual de cada fonte de energia RENOVÁVEL para os paises do top 5 e destaque da principal fonte de cada (5 consultas)

6) Bigquery: Percentual de cada fonte de energia NÃO RENOVÁVEL para os paises do top 5 e destaque da principal fonte de cada (5 consultas)

## Insight 5
"""

# Novo dataframe
df_insight_5 = df_spark_xlsx

# Criação de coluna com geração total de eletricidade por fonte renovável:

df_insight_5 = df_insight_5.withColumn('Geracao_total_de_eletricidade_por_fonte_renovavel_em_TWh',
                                         F.col('Geracao_de_eletricidade_por_biocombustiveis_em_TWh') + 
                                         F.col('Geracao_de_eletricidade_por_energia_hidreletrica_em_TWh') + 
                                         F.col('Geracao_de_eletricidade_por_energia_solar_em_TWh') + 
                                         F.col('Geracao_de_eletricidade_por_energia_eolica_em_TWh') 
                                         )

# Conversão da coluna para o tipo Float:
df_insight_5.select(F.col("Geracao_total_de_eletricidade_por_fonte_renovavel_em_TWh").cast("float"))

# Criação de coluna com consumo total de consumo de eletricidade por fonte não renovável:

df_insight_5 = df_insight_5.withColumn('Geracao_total_de_eletricidade_por_fonte_nao_renovavel_em_TWh',
                                         F.col('Geracao_de_eletricidade_por_gas_em_TWh') + 
                                         F.col('Geracao_de_eletricidade_por_carvao_em_TWh') + 
                                         F.col('Geracao_de_eletricidade_por_energia_nuclear_em_TWh') + 
                                         F.col('Geracao_de_eletricidade_por_petroleo_em_TWh') 
                                         )

# Conversão da coluna para o tipo Float:
df_insight_5.select(F.col("Geracao_total_de_eletricidade_por_fonte_nao_renovavel_em_TWh").cast("float"))

df_insight_5.createOrReplaceTempView("df_bq_5")

# Ranking de geração total de eletricidade por fonte renovável

spark.sql('SELECT Pais,Ano,Geracao_total_de_eletricidade_por_fonte_renovavel_em_TWh FROM df_bq_5 WHERE Ano == 2020 ORDER BY Geracao_total_de_eletricidade_por_fonte_renovavel_em_TWh DESC').show(50)

# Ranking de geração total de eletricidade por fonte não renovável

spark.sql('SELECT Pais,Ano,Geracao_total_de_eletricidade_por_fonte_nao_renovavel_em_TWh FROM df_bq_5 WHERE Ano == 2020 ORDER BY Geracao_total_de_eletricidade_por_fonte_nao_renovavel_em_TWh DESC').show(50)

"""## Insight 6"""

df_insight_6 = df_spark_xlsx

df_insight_6.createOrReplaceTempView("df_bq_6")

# 2020
# GERAÇÃO de fonte de energia RENOVÁVEL para os paises do top 5 de 2020

spark.sql('SELECT Pais, Ano, Geracao_de_eletricidade_por_biocombustiveis_em_TWh AS Biocombustiveis_TWh, Geracao_de_eletricidade_por_energia_hidreletrica_em_TWh AS Energia_hidreletrica_TWh, Geracao_de_eletricidade_por_energia_solar_em_TWh AS Energia_solar_TWh, Geracao_de_eletricidade_por_energia_eolica_em_TWh AS Energia_eolica_TWh FROM df_bq_6 WHERE Ano == 2020 and (Pais == "China" or Pais == "Estados_Unidos" or Pais == "India" or Pais == "Brasil" or Pais == "Canada")').show()

# TODOS OS ANOS
# GERAÇÃO de fonte de energia RENOVÁVEL para os paises do top 5 de 2020

spark.sql('SELECT Pais, Ano, Geracao_de_eletricidade_por_biocombustiveis_em_TWh AS Biocombustiveis_TWh, Geracao_de_eletricidade_por_energia_hidreletrica_em_TWh AS Energia_hidreletrica_TWh, Geracao_de_eletricidade_por_energia_solar_em_TWh AS Energia_solar_TWh, Geracao_de_eletricidade_por_energia_eolica_em_TWh AS Energia_eolica_TWh FROM df_bq_6 WHERE (Pais == "China" or Pais == "Estados_Unidos" or Pais == "India" or Pais == "Brasil" or Pais == "Canada")').show()

# 2020
# GERAÇÃO de fonte de energia NÃO RENOVÁVEL para os paises do top 5 de 2020

spark.sql('SELECT Pais, Ano, Geracao_de_eletricidade_por_gas_em_TWh AS Gas_TWh, Geracao_de_eletricidade_por_carvao_em_TWh AS Carvao_TWh, Geracao_de_eletricidade_por_energia_nuclear_em_TWh AS Energia_nuclear_TWh, Geracao_de_eletricidade_por_petroleo_em_TWh AS Petroleo_TWh FROM df_bq_6 WHERE Ano == 2020 and (Pais == "China" or Pais == "Estados_Unidos" or Pais == "India" or Pais == "Russia" or Pais == "Japao")').show()

# TODOS OS ANOS
# GERAÇÃO de fonte de energia NÃO RENOVÁVEL para os paises do top 5 de 2020

spark.sql('SELECT Pais, Ano, Geracao_de_eletricidade_por_gas_em_TWh AS Gas_TWh, Geracao_de_eletricidade_por_carvao_em_TWh AS Carvao_TWh, Geracao_de_eletricidade_por_energia_nuclear_em_TWh AS Energia_nuclear_TWh, Geracao_de_eletricidade_por_petroleo_em_TWh AS Petroleo_TWh FROM df_bq_6 WHERE (Pais == "China" or Pais == "Estados_Unidos" or Pais == "India" or Pais == "Russia" or Pais == "Japao")').show()

"""# Mongo DB

"""

#instalando pymongo
!pip install pymongo[srv]

import pymongo
from pymongo import MongoClient

# conexão com o cluster mongo
client = pymongo.MongoClient('mongodb+srv://silv4filipe:d4e5f6@projeto.it6zq.mongodb.net/myFirstDatabase?retryWrites=true&w=majority')

# Conversão para pandas

# Datasets tratados:
df_paises_final = df_spark_paises.toPandas()
df_mundo_final = df_spark_mundo.toPandas()
df_xlsx_final = df_spark_xlsx.toPandas()

# Insights:
df_insight_1_final = df_insight_1.toPandas()
df_insight_2_final = df_insight_2.toPandas()
df_insight_3_final = df_insight_3.toPandas()
df_insight_4_final = df_insight_4.toPandas()
#df_insight_5_final = df_insight_5.toPandas()
#df_insight_6_final = df_insight_6.toPandas()

# Conversão para dicionários

# Datasets tratados:
data_p = df_paises_final.to_dict(orient="records")
data_m = df_mundo_final.to_dict(orient="records")
data_x = df_xlsx_final.to_dict(orient="records")

# Insights:
data_i1 = df_insight_1_final.to_dict(orient="records")
data_i2 = df_insight_2_final.to_dict(orient="records")
data_i3 = df_insight_3_final.to_dict(orient="records")
data_i4 = df_insight_4_final.to_dict(orient="records")
#data_i5 = df_insight_5_final.to_dict(orient="records")
#data_i6 = df_insight_6_final.to_dict(orient="records")

df=client['Dataframes_finais']

# Datasets tratados:
final_p = df.df_paises
final_m = df.df_mundo
final_x = df.df_xlsx

# Insights:
final_i1 = df.df_insight_1
final_i2 = df.df_insight_2
final_i3 = df.df_insight_3
final_i4 = df.df_insight_4
final_i5 = df.df_insight_5
final_i6 = df.df_insight_6

'''final_p.insert_many(data_p)
final_m.insert_many(data_m)
final_x.insert_many(data_x)
final_a.insert_many(data_a)
final_i3.insert_many(data_i3)
final_i4.insert_many(data_i4)'''

"""# MySQL"""

# Instalando a biblioteca mysql-connector-python
!pip install mysql-connector-python

# Instalando pymysql
!pip install pymysql

# Importando as bibliotecas de conexão
import mysql.connector
from mysql.connector import Error

# Importando create_engine da biblioteca sqlalchemy
from sqlalchemy import create_engine

# Função para conexão com mysql

def conexao_db(host, user, password, db):
  conexao = None
  try:
    conexao = mysql.connector.connect(
      host = host,
      user = user,
      passwd = password,
      database = db     
    )
    print(f"Conexão com o banco {db} realizada com Sucesso!")
  except:
    print(f"Erro ao conectar ao banco {db}! '{Error}'")

  return conexao

# Criação
conexao = conexao_db("35.247.240.99", "root", "a1b2c3", "db_projeto_originais")
cur = conexao.cursor()
engine = create_engine("mysql+pymysql://root:a1b2c3@35.247.240.99/db_projeto_originais")

# Operações no banco de dados 
cur.execute('Show databases')
cur.fetchall()

cur.execute('USE db_projeto_originais;')
cur.fetchall()

cur.execute('show tables;')
cur.fetchall()

# Transformando os DataFrames para formado SQL
'''
df_sql_mundo = df_mundo.to_sql("continent_consumption_twh", con = engine, if_exists='replace', index = False)
df_sql_paises = df_paises.to_sql("country_consumption_twh", con = engine, if_exists='replace', index = False)
df_sql_xlsx = df_xlsx.to_sql("owid_energy", con = engine, if_exists='replace', index = False)
'''

"""# Exportando para bucket"""

df_paises_final.to_csv('gs://projeto_grupo/paises_final.csv', index = False)
df_mundo_final.to_csv('gs://projeto_grupo/mundo_final.csv', index = False)
df_xlsx_final.to_csv('gs://projeto_grupo/xlsx_final.csv', index = False)
df_insight_1_final.to_csv('gs://projeto_grupo/datasets_tratados/insight_1_final.csv', index = False)
df_insight_2_final.to_csv('gs://projeto_grupo/datasets_tratados/insight_2_final.csv', index = False)
df_insight_3_final.to_csv('gs://projeto_grupo/datasets_tratados/insight_3_final.csv', index = False)
df_insight_4_final.to_csv('gs://projeto_grupo/datasets_tratados/insight_4_final.csv', index = False)
df_insight_5_final.to_csv('gs://projeto_grupo/datasets_tratados/insight_5_final.csv', index = False)
df_insight_6_final.to_csv('gs://projeto_grupo/datasets_tratados/insight_6_final.csv', index = False)